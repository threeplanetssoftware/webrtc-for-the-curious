<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="What is WebRTC Signaling? #  When you create a WebRTC agent it knows nothing about the other peer. It has no idea who it is going to connect with or what they are going to send! Signaling is the initial bootstrapping that makes the call possible. After these values are exchanged the WebRTC agents then can communicate directly with each other.
Signaling messages are just text. The WebRTC agents don&rsquo;t care how they are transported."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Signaling"><meta property="og:description" content="What is WebRTC Signaling? #  When you create a WebRTC agent it knows nothing about the other peer. It has no idea who it is going to connect with or what they are going to send! Signaling is the initial bootstrapping that makes the call possible. After these values are exchanged the WebRTC agents then can communicate directly with each other.
Signaling messages are just text. The WebRTC agents don&rsquo;t care how they are transported."><meta property="og:type" content="article"><meta property="og:url" content="https://webrtcforthecurious.com/docs/02-signaling/"><meta property="article:modified_time" content="2020-10-10T14:21:36-04:00"><meta property="og:site_name" content="WebRTC for the Curious"><title>Signaling | WebRTC for the Curious</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=alternate hreflang=tr href=https://webrtcforthecurious.com/tr/docs/02-signaling/ title=Signaling><link rel=stylesheet href=/book.min.6cd8553a6854f4812343f0f0c8baca31271e686434f381fbe3c7226f66639176.css integrity="sha256-bNhVOmhU9IEjQ/DwyLrKMSceaGQ084H748cib2ZjkXY="><script defer src=/en.search.min.0a9c82fb228958103802c198e18a5331331abc9d65109990e54aeb8ede1d19f8.js integrity="sha256-CpyC+yKJWBA4AsGY4YpTMTMavJ1lEJmQ5Urrjt4dGfg="></script></head><body><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=/><span>WebRTC for the Curious</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/docs/01-what-why-and-how/>What, Why and How</a></li><li><a href=/docs/02-signaling/ class=active>Signaling</a></li><li><a href=/docs/03-connecting/>Connecting</a></li><li><a href=/docs/04-securing/>Securing</a></li><li><a href=/docs/05-media-communication/>Media Communication</a></li><li><a href=/docs/06-data-communication/>Data Communication</a></li><li><a href=/docs/07-applied-webrtc/>Applied WebRTC</a></li><li><a href=/docs/08-debugging/>Debugging</a></li><li><a href=/docs/09-history-of-webrtc/>History</a></li><li><a href=/docs/10-faq/>FAQ</a></li><li><a href=/docs/11-contributing/>Contributing</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Signaling</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#how-does-webrtc-signaling-work>How does WebRTC signaling work?</a></li><li><a href=#what-is-the-session-description-protocol-sdp>What is the <em>Session Description Protocol</em> (SDP)?</a><ul><li><a href=#how-to-read-the-sdp>How to read the SDP</a></li><li><a href=#webrtc-only-uses-some-sdp-keys>WebRTC only uses some SDP keys</a></li><li><a href=#media-descriptions-in-a-session-description>Media Descriptions in a Session Description</a></li><li><a href=#full-example>Full Example</a></li></ul></li><li><a href=#how-session-description-protocol-and-webrtc-work-together>How <em>Session Description Protocol</em> and WebRTC work together</a><ul><li><a href=#what-are-offers-and-answers>What are Offers and Answers?</a></li><li><a href=#transceivers-are-for-sending-and-receiving>Transceivers are for sending and receiving</a></li><li><a href=#sdp-values-used-by-webrtc>SDP Values used by WebRTC</a></li><li><a href=#example-of-a-webrtc-session-description>Example of a WebRTC Session Description</a></li><li><a href=#further-topics>Further Topics</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=what-is-webrtc-signaling>What is WebRTC Signaling?
<a class=anchor href=#what-is-webrtc-signaling>#</a></h1><p>When you create a WebRTC agent it knows nothing about the other peer. It has no idea who it is going to connect with or what they are going to send!
Signaling is the initial bootstrapping that makes the call possible. After these values are exchanged the WebRTC agents then can communicate directly with each other.</p><p>Signaling messages are just text. The WebRTC agents don&rsquo;t care how they are transported. They are commonly shared via Websockets, but not a requirement.</p><h2 id=how-does-webrtc-signaling-work>How does WebRTC signaling work?
<a class=anchor href=#how-does-webrtc-signaling-work>#</a></h2><p>WebRTC uses an existing protocol called the Session Description Protocol. Via this protocol, the two WebRTC Agents will share all the state required to establish a connection. The protocol itself is simple to read and understand.
The complexity comes from understanding all the values that WebRTC populates it with.</p><p>This protocol is not specific to WebRTC. We will learn the Session Description Protocol first without even talking about WebRTC. WebRTC only really takes advantage of a subset of the protocol so we are only going to cover what we need.
After we understand the protocol we will move on to its applied usage in WebRTC.</p><h2 id=what-is-the-session-description-protocol-sdp>What is the <em>Session Description Protocol</em> (SDP)?
<a class=anchor href=#what-is-the-session-description-protocol-sdp>#</a></h2><p>The Session Description Protocol is defined in <a href=https://tools.ietf.org/html/rfc4566>RFC 4566</a>. It is a key/value protocol with a newline after each value. It will feel similar to an INI file.
A Session Description then contains an unlimited amount of Media Descriptions. Mentally you can model it as a Session Description contains an array of Media Descriptions.</p><p>A Media Description usually maps to a single stream of media. So if you wanted to describe a call with three video streams and two audio tracks you would have five Media Descriptions.</p><h3 id=how-to-read-the-sdp>How to read the SDP
<a class=anchor href=#how-to-read-the-sdp>#</a></h3><p>Every line in a Session Description will start with a single character, this is your key. It will then be followed by an equal sign. Everything after that equal sign is the value. After the value is complete you will have a newline.</p><p>The Session Description Protocol defines all the keys that are valid. You can only use letters for keys as defined in the protocol. These keys all have significant meaning, which will be explained later.</p><p>Take this Session Description excerpt.</p><pre><code>a=my-sdp-value
a=second-value
</code></pre><p>You have two lines. Each with the key <code>a</code>. The first line has the value <code>my-sdp-value</code>, the second line has the value <code>second-value</code>.</p><h3 id=webrtc-only-uses-some-sdp-keys>WebRTC only uses some SDP keys
<a class=anchor href=#webrtc-only-uses-some-sdp-keys>#</a></h3><p>Not all key values defined by the Session Description Protocol are used by WebRTC. The following are the only keys you need to understand. Don&rsquo;t worry about fully understanding yet, but this will be a handy reference in the future.</p><ul><li><code>v</code> - Version, should be equal to &lsquo;0&rsquo;</li><li><code>o</code> - Origin, contains a unique ID useful for renegotiations</li><li><code>s</code> - Session Name, should be equal to &lsquo;-&rsquo;</li><li><code>t</code> - Timing, should be equal to &lsquo;0 0&rsquo;</li><li><code>m</code> - Media Description, described in detail below</li><li><code>a</code> - Attribute, free text field this is the most common line in WebRTC</li><li><code>c</code> - Connection Data, should be equal to &lsquo;IN IP4 0.0.0.0&rsquo;</li></ul><h3 id=media-descriptions-in-a-session-description>Media Descriptions in a Session Description
<a class=anchor href=#media-descriptions-in-a-session-description>#</a></h3><p>A Session Description can contain an unlimited amount of Media Descriptions.</p><p>A Media Description definition contains a list of formats. These formats map to RTP Payload Types. The actual codec is then defined by an Attribute with the value <code>rtpmap</code> in the Media Description.
The importance of RTP and RTP Payload Types is discussed later in the Media chapter. Each Media Description then can contain an unlimited amount of attributes.</p><p>Take this Session Description excerpt.</p><pre><code>v=0
m=audio 4000 RTP/AVP 111
a=rtpmap:111 OPUS/48000/2
m=video 4000 RTP/AVP 96
a=rtpmap:96 VP8/90000
a=my-sdp-value
</code></pre><p>You have two Media Descriptions, one of type audio with fmt <code>111</code> and one of type video with fmt <code>96</code>. The first Media Description has only one attribute. This attribute maps the Payload Type <code>111</code> to Opus.
The second Media Description has two attributes. The first attribute maps the Payload Type <code>96</code> to be VP8, and the second attribute is just <code>my-sdp-value</code></p><h3 id=full-example>Full Example
<a class=anchor href=#full-example>#</a></h3><p>The following brings all the concepts we have talked about together. These are all the features of the Session Description Protocol that WebRTC uses.
If you can read this you can read any WebRTC Session Description!</p><pre><code>v=0
o=- 0 0 IN IP4 127.0.0.1
s=-
c=IN IP4 127.0.0.1
t=0 0
m=audio 4000 RTP/AVP 111
a=rtpmap:111 OPUS/48000/2
m=video 4002 RTP/AVP 96
a=rtpmap:96 VP8/90000
</code></pre><ul><li><code>v</code>, <code>o</code>, <code>s</code>, <code>c</code>, <code>t</code> are defined but they do not affect the WebRTC session.</li><li>You have two Media Descriptions. One of type <code>audio</code> and one of type <code>video</code>.</li><li>Each of those has one attribute. This attribute configures details of the RTP pipeline, which is discussed in the &lsquo;Media Communication&rsquo; chapter.</li></ul><h2 id=how-session-description-protocol-and-webrtc-work-together>How <em>Session Description Protocol</em> and WebRTC work together
<a class=anchor href=#how-session-description-protocol-and-webrtc-work-together>#</a></h2><p>The next piece of the puzzle is understanding how WebRTC uses the Session Description Protocol.</p><h3 id=what-are-offers-and-answers>What are Offers and Answers?
<a class=anchor href=#what-are-offers-and-answers>#</a></h3><p>WebRTC uses an offer/answer model. All this means is that one WebRTC Agent makes an &lsquo;Offer&rsquo; to start the call, and the other WebRTC Agents &lsquo;Answers&rsquo; if it is willing to accept what has been offered.</p><p>This gives the answerer a chance to reject codecs, Media Descriptions. This is how two peers can understand what they are willing to exchange.</p><h3 id=transceivers-are-for-sending-and-receiving>Transceivers are for sending and receiving
<a class=anchor href=#transceivers-are-for-sending-and-receiving>#</a></h3><p>Transceivers is a WebRTC specific concept that you will see in the API. What it is doing is exposing the &lsquo;Media Description&rsquo; to the Javascript API. Each Media Description becomes a Transceiver.
Every time you create a Transceiver a new Media Description is added to the local Session Description.</p><p>Each Media Description in WebRTC will have a direction attribute. This allows a WebRTC Agent to declare &lsquo;I am going to send you this codec, but I am not willing to accept anything back&rsquo;. There are four valid values</p><ul><li><code>send</code></li><li><code>recv</code></li><li><code>sendrecv</code></li><li><code>inactive</code></li></ul><h3 id=sdp-values-used-by-webrtc>SDP Values used by WebRTC
<a class=anchor href=#sdp-values-used-by-webrtc>#</a></h3><p>This list is not extensive, but this is a list of common attributes that you will see in a Session Description from a WebRTC Agent. Many of these values control the subsystems that we haven&rsquo;t discussed yet.</p><h5 id=groupbundle><code>group:BUNDLE</code>
<a class=anchor href=#groupbundle>#</a></h5><p>Bundling is the act of running multiple types of traffic over one connection. Some WebRTC implementations use a dedicated connection per media stream. Bundling should be preferred.</p><h5 id=fingerprintsha-256><code>fingerprint:sha-256</code>
<a class=anchor href=#fingerprintsha-256>#</a></h5><p>This is a hash of the certificate the peer is using for DTLS. After the DTLS handshake is completed you compare this to the actual certificate to confirm you are communicating with whom you expect.</p><h5 id=setup><code>setup:</code>
<a class=anchor href=#setup>#</a></h5><p>This controls the DTLS Agent behavior. This determines if it runs as a client or server after ICE has connected.</p><ul><li><code>setup:active</code> - Run as DTLS Client</li><li><code>setup:passive</code> - Run as DTLS Server</li><li><code>setup:actpass</code> - Ask other WebRTC Agent to choose</li></ul><h5 id=ice-ufrag><code>ice-ufrag</code>
<a class=anchor href=#ice-ufrag>#</a></h5><p>This is the user fragment value for the ICE Agent. Used for the authentication of ICE Traffic.</p><h5 id=ice-pwd><code>ice-pwd</code>
<a class=anchor href=#ice-pwd>#</a></h5><p>This is the password for the ICE Agent. Used for authentication of ICE Traffic.</p><h5 id=rtpmap><code>rtpmap</code>
<a class=anchor href=#rtpmap>#</a></h5><p>This value is used to map a specific codec to a RTP Payload Type. Payload types are not static so every call the Offerer decides the Payload types for each codec.</p><h5 id=fmtp><code>fmtp</code>
<a class=anchor href=#fmtp>#</a></h5><p>Defines additional values for one Payload Type. This is useful to communicate a specific video profile or encoder setting.</p><h5 id=candidate><code>candidate</code>
<a class=anchor href=#candidate>#</a></h5><p>This is an ICE Candidate that comes from the ICE Agent. This is one possible address that the WebRTC Agent is available on. These are fully explained in the next chapter.</p><h5 id=ssrc><code>ssrc</code>
<a class=anchor href=#ssrc>#</a></h5><p>A SSRC defines a single media stream track.</p><p><code>label</code> is the id for this individual stream. <code>mslabel</code> is the id for a container that can multiple streams inside of it.</p><h3 id=example-of-a-webrtc-session-description>Example of a WebRTC Session Description
<a class=anchor href=#example-of-a-webrtc-session-description>#</a></h3><p>The following is a complete Session Description generated by a WebRTC Client.</p><pre><code>v=0
o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0
s=-
t=0 0
a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E
a=group:BUNDLE 0 1
m=audio 9 UDP/TLS/RTP/SAVPF 111
c=IN IP4 0.0.0.0
a=setup:active
a=mid:0
a=ice-ufrag:CsxzEWmoKpJyscFj
a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd
a=rtcp-mux
a=rtcp-rsize
a=rtpmap:111 opus/48000/2
a=fmtp:111 minptime=10;useinbandfec=1
a=ssrc:350842737 cname:yvKPspsHcYcwGFTw
a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV
a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw
a=ssrc:350842737 label:DfQnKjQQuwceLFdV
a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV
a=sendrecv
a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0
a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0
a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0
a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0
a=end-of-candidates
m=video 9 UDP/TLS/RTP/SAVPF 96
c=IN IP4 0.0.0.0
a=setup:active
a=mid:1
a=ice-ufrag:CsxzEWmoKpJyscFj
a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd
a=rtcp-mux
a=rtcp-rsize
a=rtpmap:96 VP8/90000
a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ
a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW
a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ
a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW
a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW
a=sendrecv
a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0
a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0
a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0
a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0
a=end-of-candidates
</code></pre><p>This is what we know from this message</p><ul><li>We have two media sections, one audio, and one video</li><li>Each of those is a <code>sendrecv</code> Transceiver. We are getting two streams, and we can send two back.</li><li>We have ICE Candidates and Authentication details so we can attempt to connect</li><li>We have a certificate fingerprint, so we can have a secure call</li></ul><h3 id=further-topics>Further Topics
<a class=anchor href=#further-topics>#</a></h3><p>In later versions of this book, the following topics will also be addressed. If you have more questions please submit a Pull Request!</p><ul><li>Renegotiation</li><li>Simulcast</li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div class=book-languages tabindex=0 aria-haspopup=true><ul><li class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
English</li></ul><ul class=book-languages-list><li class=active><a href=https://webrtcforthecurious.com/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
English</a></li><li><a href=https://webrtcforthecurious.com/tr/docs/02-signaling/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
Turkish</a></li></ul></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/commit/5455d50af6f9f7df00e547e8d83296958b084968 title="Last modified by Three Planets Software | October 10, 2020" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>October 10, 2020</span></a></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/edit/master/content//docs/02-signaling.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#how-does-webrtc-signaling-work>How does WebRTC signaling work?</a></li><li><a href=#what-is-the-session-description-protocol-sdp>What is the <em>Session Description Protocol</em> (SDP)?</a><ul><li><a href=#how-to-read-the-sdp>How to read the SDP</a></li><li><a href=#webrtc-only-uses-some-sdp-keys>WebRTC only uses some SDP keys</a></li><li><a href=#media-descriptions-in-a-session-description>Media Descriptions in a Session Description</a></li><li><a href=#full-example>Full Example</a></li></ul></li><li><a href=#how-session-description-protocol-and-webrtc-work-together>How <em>Session Description Protocol</em> and WebRTC work together</a><ul><li><a href=#what-are-offers-and-answers>What are Offers and Answers?</a></li><li><a href=#transceivers-are-for-sending-and-receiving>Transceivers are for sending and receiving</a></li><li><a href=#sdp-values-used-by-webrtc>SDP Values used by WebRTC</a></li><li><a href=#example-of-a-webrtc-session-description>Example of a WebRTC Session Description</a></li><li><a href=#further-topics>Further Topics</a></li></ul></li></ul></nav></aside></main></body></html>